{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Finger print classifier Notebook</h1>\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>First let us import Our necessary packages</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "from keras.initializers import glorot_uniform\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Our Preprocessing steps are:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1-Read text files beside every image and create .csv file which contain picture info Related with it's id</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMapDataset(path):\n",
    "    onlyfiles = ([f.replace('.txt', '') for f in listdir(path) if isfile(join(path, f))])\n",
    "\n",
    "    dataframe['id'] = onlyfiles\n",
    "    content = []\n",
    "    gender = []\n",
    "    cl = []\n",
    "    for i in range(len(onlyfiles)):\n",
    "        with open(path + '/' + str(onlyfiles[i]) + '.txt') as f:\n",
    "            content.append(f.readlines())\n",
    "    for c in content:\n",
    "        c = [x.strip() for x in c]\n",
    "        gender.append(c[0].split(' ')[1])\n",
    "        cl.append(c[1].split(' ')[1])\n",
    "    dataframe['gender'] = gender\n",
    "    dataframe['class'] = cl\n",
    "    dataframe.to_csv('dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2-We Want to split Our Images into Train , CrossValidation and Test sets\n",
    "        But We Need To ensure Data shuffled for Good Representation of all classes in train, test and validation sets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitImages(path):\n",
    "   \n",
    "    df = pd.read_csv(path)\n",
    "    ids = pd.DataFrame(df)\n",
    "    ids_shuffeled = ids.sample(frac=1, random_state=1)\n",
    "    ids_shuffeled['gender'] = ids_shuffeled['gender'].map({'M': 0, 'F': 1})\n",
    "    ids_shuffeled['class'] = ids_shuffeled['class'].map({'A': 0, 'L': 1, 'T':2, 'R':3, 'W':4})\n",
    "    train_df_x = pd.DataFrame(data=ids_shuffeled[:2285].drop('class', 1))\n",
    "    crossVal_df_x = pd.DataFrame(data=ids_shuffeled[2285:2885].drop('class', 1))\n",
    "    test_df_x = pd.DataFrame(data=ids_shuffeled[2885:].drop('class', 1))\n",
    "    train_labels = pd.DataFrame(data = ids_shuffeled['class'][:2285])\n",
    "    crossVal_labels = pd.DataFrame(data=ids_shuffeled['class'][2285:2885])\n",
    "    test_labels = pd.DataFrame(data=ids_shuffeled['class'][2885:])\n",
    "    train_df_x.to_csv('Train.csv', index=False)\n",
    "    crossVal_df_x.to_csv('val.csv')\n",
    "    test_df_x.to_csv('test.csv')\n",
    "\n",
    "    return train_df_x, crossVal_df_x, test_df_x, train_labels, crossVal_labels,test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3-Create Subdirectories for each class (from our  a,w,r,l,t classes) because that is the format which our image datagenerator class waiting for</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_classes(path):\n",
    "    df = pd.read_csv(path, index_col=False)\n",
    "    class_a=[] ; class_t=[]; class_r=[]; class_w=[]; class_l = []\n",
    "    class_a.extend(df.id[(df['class'] == 'A')])\n",
    "    class_t.extend(df.id[(df['class'] == 'T')])\n",
    "    class_r.extend(df.id[(df['class'] == 'R')])\n",
    "    class_w.extend(df.id[(df['class'] == 'W')])\n",
    "    class_l.extend(df.id[(df['class'] == 'L')])\n",
    "\n",
    "    return class_a, class_t, class_r, class_w, class_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subfolders(a,t,r,w,l):\n",
    "    class_a = a\n",
    "    class_t = t\n",
    "    class_r = r\n",
    "    class_w = w\n",
    "    class_l = l\n",
    "    for i in class_a:\n",
    "        srcfile = 'Dataset/sd04/png_txt/Untitled Folder/' + str(i) + '.png'\n",
    "        dstroot = 'Dataset/sd04/png_txt/figs/test/a'\n",
    "        assert not os.path.isabs(srcfile)\n",
    "        dstdir = os.path.join(dstroot, os.path.dirname(str(i) + '.png'))\n",
    "\n",
    "        shutil.copy(srcfile, dstdir)\n",
    "    for j in class_t:\n",
    "        srcfile = 'Dataset/sd04/png_txt/Untitled Folder/' + str(j) + '.png'\n",
    "        dstroot = 'Dataset/sd04/png_txt/figs/test/t'\n",
    "        assert not os.path.isabs(srcfile)\n",
    "        dstdir = os.path.join(dstroot, os.path.dirname(str(j) + '.png'))\n",
    "\n",
    "        shutil.copy(srcfile, dstdir)\n",
    "    for k in class_r:\n",
    "        srcfile = 'Dataset/sd04/png_txt/Untitled Folder/' + str(k) + '.png'\n",
    "        dstroot = 'Dataset/sd04/png_txt/figs/test/r'\n",
    "        assert not os.path.isabs(srcfile)\n",
    "        dstdir = os.path.join(dstroot, os.path.dirname(str(k) + '.png'))\n",
    "\n",
    "        shutil.copy(srcfile, dstdir)\n",
    "\n",
    "    for l in class_l:\n",
    "        srcfile = 'Dataset/sd04/png_txt/Untitled Folder/' + str(l) + '.png'\n",
    "        dstroot = 'Dataset/sd04/png_txt/figs/test/l'\n",
    "        assert not os.path.isabs(srcfile)\n",
    "        dstdir = os.path.join(dstroot, os.path.dirname(str(l) + '.png'))\n",
    "\n",
    "        shutil.copy(srcfile, dstdir)\n",
    "\n",
    "    for w in class_w:\n",
    "        srcfile = 'Dataset/sd04/png_txt/Untitled Folder/' + str(w) + '.png'\n",
    "        dstroot = 'Dataset/sd04/png_txt/figs/test/w'\n",
    "        assert not os.path.isabs(srcfile)\n",
    "        dstdir = os.path.join(dstroot, os.path.dirname(str(w) + '.png'))\n",
    "\n",
    "        shutil.copy(srcfile, dstdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4-last step using imageDatageneartor class from keras and apply some data augmentation on images to build powerful convnet model with little amount of data</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "train_generator = ImageDataGenerator(rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "\n",
    "        ).flow_from_directory(\n",
    "        directory='Dataset/sd04/png_txt/figs/train',  # this is the target directory\n",
    "        target_size=(64, 64),  # all images will be resized to 64x64\n",
    "        batch_size=16,\n",
    "        class_mode='categorical',\n",
    "        color_mode='rgb',)\n",
    "\n",
    "crossVal_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        directory='Dataset/sd04/png_txt/figs/test',  \n",
    "        target_size=(64, 64),  \n",
    "        batch_size=16,\n",
    "        class_mode='categorical',\n",
    "        color_mode='rgb')\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        directory='Dataset/sd04/png_txt/figs/validation',  \n",
    "        target_size=(64, 64),  \n",
    "        batch_size=16,\n",
    "        class_mode='categorical',\n",
    "        color_mode='rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>What are Convolutional Neural Networks and why are they important?</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Convolutional Neural Networks (ConvNets or CNNs) are a category of Neural Networks that have proven very effective in areas such as image recognition and classification. ConvNets have been successful in identifying faces, objects and traffic signs apart from powering vision in robots and self driving cars.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/model.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>We will discuss the following topics:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1-ConvLayer\n",
    "\n",
    "2-Pool Layer</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1-Convolutional Layer:\n",
    "A convolution layer transforms an input volume into an output volume of different size, as shown below.</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/conv_nn.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2-PoolingLayer:\n",
    "The pooling (POOL) layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. The two types of pooling layers are:\n",
    "Max-pooling layer: slides an ( f,ff,f ) window over the input and stores the max value of the window in the output.\n",
    "Average-pooling layer: slides an ( f,ff,f ) window over the input and stores the average value of the window in the output.</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/max_pool.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ave-pool.png\" / >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Why Resnet50?</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The main benefit of a very deep network is that it can represent very complex functions. It can also learn features at many different levels of abstraction, from edges (at the lower layers) to very complex features (at the deeper layers). However, using a deeper network doesn't always help. A huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent unbearably slow. More specifically, during gradient descent, as you backprop from the final layer back to the first layer, you are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero (or, in rare cases, grow exponentially quickly and \"explode\" to take very large values).</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/graph.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>What's new in Resnet50</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/main_pth.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"images/shortcut_path.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The image on the left shows the \"main path\" through the network. The image on the right adds a shortcut to the main path. By stacking these ResNet blocks on top of each other, you can form a very deep network.\n",
    "shortcut also makes it very easy for one of the blocks to learn an identity function. This means that you can stack on additional ResNet blocks with little risk of harming training set performance. (There is also some evidence that the ease of learning an identity function--even more than skip connections helping with vanishing gradients--accounts for ResNets' remarkable performance.)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Blocks in our Resnet50:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1-The identity block</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/iden.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2-Conv Block</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/conv.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The fullcode of Resnet50 to classify fingerprints </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "\n",
    "\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. You'll need this later to add back to the main path.\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,  name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (â‰ˆ2 lines)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,  name=bn_name_base + '2c')(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(F1, (1, 1), strides=(s, s), name=conv_name_base + '2a',\n",
    "               kernel_initializer=glorot_uniform(seed=0), padding='valid')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    X = Conv2D(F2, (f, f), strides=(1, 1), name=conv_name_base + '2b',\n",
    "               kernel_initializer=glorot_uniform(seed=0), padding='same')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F3, (1, 1), strides=(1, 1), name=conv_name_base + '2c',\n",
    "               kernel_initializer=glorot_uniform(seed=0), padding='valid')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    X_shortcut = Conv2D(filters=F3, strides=(s, s), kernel_size=(1, 1),\n",
    "                        padding='valid',name=conv_name_base + '1',\n",
    "                        kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(64, 64, 3), classes=5):\n",
    "  \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "\n",
    "    X = convolutional_block(X,f=3,block='a',filters = [128, 128, 256],stage=3,s=2)\n",
    "    X = identity_block(X, f = 3, filters = [128, 128, 256], stage = 3, block = 'b')\n",
    "    X = identity_block(X, f = 3, filters = [128, 128, 256], stage = 3, block = 'c')\n",
    "    X = identity_block(X, f = 3, filters = [128, 128, 256], stage = 3, block = 'd')\n",
    "\n",
    "    X = convolutional_block(X,f=3,block='a',filters = [256, 256, 1024],stage=4,s=2)\n",
    "    X = identity_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'b')\n",
    "    X = identity_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'c')\n",
    "    X = identity_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'd')\n",
    "    X = identity_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'e')\n",
    "    X = identity_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block = 'f')\n",
    "\n",
    "    X = convolutional_block(X, f=3, block='a', filters=[512, 512, 2048],stage=5,s=2)\n",
    "    X = identity_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block = 'b')\n",
    "    X = identity_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block = 'c')\n",
    "\n",
    "    X = AveragePooling2D(pool_size=(2, 2), name=\"avg_pool\")(X)\n",
    "\n",
    "\n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 5)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "Hist = model.fit_generator(train_generator, steps_per_epoch=2285, validation_data=crossVal_generator,\n",
    "                    validation_steps=1115,epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Here we plot some statistics about loss,accuracy and num of epochs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict_final = {}  # Create an empty dictionary\n",
    "with open('History10.pickle', 'rb') as f:\n",
    "    my_dict_final.update(pickle.load(f))   # Update contents of file1 to the dictionary\n",
    "\n",
    "with open('History9.pickle', 'rb') as f:\n",
    "    my_dict_final.update(pickle.load(f)) # Update contents of file2 to the dictionary\n",
    "with open('History8.pickle', 'rb') as f:\n",
    "    my_dict_final.update(pickle.load(f))\n",
    "with open('History7.pickle', 'rb') as f:\n",
    "    my_dict_final.update(pickle.load(f))\n",
    "with open('History6.pickle', 'rb') as f:\n",
    "    my_dict_final.update(pickle.load(f))\n",
    "with open('History5.pickle', 'rb') as f:\n",
    "    my_dict_final.update(pickle.load(f))\n",
    "with open('History4.pickle', 'rb') as f:\n",
    "    my_dict_final.update(pickle.load(f))\n",
    "with open('History3.pickle', 'rb') as f:\n",
    "    my_dict_final.update(pickle.load(f))\n",
    "with open('History2.pickle', 'rb') as f:\n",
    "    my_dict_final.update(pickle.load(f))\n",
    "with open('History.pickle', 'rb') as f:\n",
    "    my_dict_final.update(pickle.load(f))\n",
    "\n",
    "\n",
    "his = pickle.load(open('History10.pickle', 'rb'))\n",
    "\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(my_dict_final['acc'])\n",
    "plt.plot(my_dict_final['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(my_dict_final['loss'])\n",
    "plt.plot(my_dict_final['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Figure_1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Figure_2.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}